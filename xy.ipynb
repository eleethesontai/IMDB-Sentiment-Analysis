{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        working with one of the best shakespeare sourc...\n",
       "1        well tremors i the original started off in and...\n",
       "2        ouch this one was a bit painful to sit through...\n",
       "3        ive seen some crappy movies in my life but thi...\n",
       "4         carriers follows the exploits of two guys and...\n",
       "                               ...                        \n",
       "49995    this movie is certainly well constructed begin...\n",
       "49996    nice to see a comedy for grown ups masterfully...\n",
       "49997    jean renoirs homage to the paris of the late t...\n",
       "49998    what are the movies i mean what are movies mad...\n",
       "49999    i saw this movie on tv and loved it i am a rea...\n",
       "Name: x, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['x'] = samples['Review'].str.lower()\n",
    "samples['x'] = samples['x'].str.replace(r'[^a-z\\s\\']', ' ', regex=True)\n",
    "samples['x'] = samples['x'].str.replace(r'\\'', '', regex=True)\n",
    "samples['x'] = samples['x'].str.replace(r'\\s+', ' ', regex=True)\n",
    "samples['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train_from_iterator(samples['x'], vocab_size=4096, min_frequency=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['x'] = samples['x'].apply(lambda x: tokenizer.encode(x).ids)\n",
    "tokenized_length = samples['x'].apply(len).max()\n",
    "samples['x'] = samples['x'].apply(lambda x: (([0]*tokenized_length)+x)[-tokenized_length:])\n",
    "samples['x'] = samples['x'].apply(lambda x: np.array(x))\n",
    "\n",
    "tokenized_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(samples['x'].tolist()).astype(np.uint16)\n",
    "y = np.array(samples['Sentiment'].tolist()).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('xy.h5', 'w')\n",
    "\n",
    "file.create_dataset('x', data=x)\n",
    "file.create_dataset('y', data=y)\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
